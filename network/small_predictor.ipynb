{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, subprocess\n",
    "import tqdm\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from neuralNetwork import NeuralNetwork, In_between_epochs\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from helper import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NeuralNetwork):\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_0 = nn.Linear(input_shape, input_shape * 4)\n",
    "        self.linear_1 = nn.Linear(input_shape * 4, input_shape * 3)\n",
    "        self.linear_2 = nn.Linear(input_shape * 3, input_shape * 2)\n",
    "        self.linear_3 = nn.Linear(input_shape * 2, input_shape * 1)\n",
    "        self.linear_4 = nn.Linear(input_shape, output_shape * 10)\n",
    "        self.linear_5 = nn.Linear(output_shape * 10, output_shape * 5)\n",
    "        self.linear_6 = nn.Linear(output_shape * 5, output_shape * 3)\n",
    "        self.output = nn.Linear(output_shape * 3, output_shape)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.linear_0(input)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear_1(out) \n",
    "        out = self.relu(out)\n",
    "        out = self.linear_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear_3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear_4(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.linear_5(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear_6(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "    \n",
    "class EarlyStopping(In_between_epochs):\n",
    "    def __init__(self, delta, patience):\n",
    "        self.delta = delta\n",
    "        self.patience = patience\n",
    "        self.current_patience = 0\n",
    "        self.best_valid_loss = 100000000000000000000\n",
    "        self.best_model = None\n",
    "        self.epochs = 0\n",
    "    \n",
    "    def __call__(self, model:torch.nn.Module, loaders:dict[str,torch.utils.data.DataLoader], device:'torch.device|str', output_extraction_function, losses:dict[str, float]) -> bool:\n",
    "        self.epochs += 1\n",
    "        if losses[\"validation\"] < self.best_valid_loss - self.delta:\n",
    "            self.best_valid_loss = losses[\"validation\"]\n",
    "            if self.best_model is None:\n",
    "                self.best_model = model\n",
    "            self.best_model.load_state_dict(model.state_dict())\n",
    "            self.current_patience = 0\n",
    "        else:\n",
    "            self.current_patience += 1\n",
    "            if self.current_patience >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "    def reset(self):\n",
    "        self.current_patience = 0\n",
    "        self.epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train, validation, min_lr, start_lr, early_stopping, frac, device):\n",
    "    tot_train_data, tot_val_data = [], []\n",
    "    lr = start_lr\n",
    "    while lr > min_lr:\n",
    "        train_data, validation_data = model.train_network(train, \n",
    "                        validation, \n",
    "                        torch.optim.Adam, \n",
    "                        loss_function=nn.CrossEntropyLoss(),\n",
    "                        device=device, \n",
    "                        batch_size=32,\n",
    "                        verbose=False, \n",
    "                        output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                        metrics={\n",
    "                        \"accuracy\": accuracy_score, \n",
    "                        \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                        in_between_epochs = {\"early_stopping\": early_stopping},\n",
    "                        learning_rate=lr,\n",
    "                        epochs=30)\n",
    "        train_data[\"epochs\"] = early_stopping.epochs\n",
    "        train_data[\"lr\"] = lr\n",
    "        validation_data[\"epochs\"] = early_stopping.epochs\n",
    "        validation_data[\"lr\"] = lr\n",
    "        tot_train_data.append(train_data)\n",
    "        tot_val_data.append(validation_data)\n",
    "        model.load_state_dict(early_stopping.best_model.state_dict())\n",
    "        lr = lr * frac\n",
    "        early_stopping.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/datasets/dataset_CoveringArray-2024-05-09.json\")\n",
    "dataset = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset creation: 100%|██████████| 2236/2236 [01:00<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy for validation (fold 0): 0.7205882352941176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset creation: 100%|██████████| 2236/2236 [00:59<00:00, 37.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy for validation (fold 1): 0.6911764705882353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset creation: 100%|██████████| 2236/2236 [00:58<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy for validation (fold 2): 0.75\n"
     ]
    }
   ],
   "source": [
    "folds = [0, 1, 2]\n",
    "models = []\n",
    "for fold in folds:\n",
    "    df = pd.read_csv(f\"../data/csv_features/features_covering_array_fold_{fold}.csv\")\n",
    "    combinations = [t[\"combination\"] for t in dataset[0][\"all_times\"]]\n",
    "    x = []\n",
    "    y = []\n",
    "    for datapoint in tqdm.tqdm(dataset, \"dataset creation\"):\n",
    "        instance = datapoint[\"instance_name\"]\n",
    "        features = df[df[\"inst\"] == instance].to_dict()\n",
    "        idx = list(features[\"inst\"].keys())[0]\n",
    "        features = {key: features[key][idx] for key in features.keys()}\n",
    "        keys = list(features.keys())\n",
    "        keys.pop(keys.index(\"inst\"))\n",
    "        keys.pop(keys.index(\"time\"))\n",
    "        features = [features[key] for key in keys]\n",
    "        x.append(torch.tensor(features))\n",
    "        correct_result = torch.zeros(len(combinations))\n",
    "        correct_result[combinations.index(datapoint[\"combination\"])] = 1.\n",
    "        y.append(correct_result)\n",
    "    train_dataloader, validation_dataloader, test_dataloader = get_dataloader(x, y, 32, [fold])\n",
    "    input_shape = len(x[0])\n",
    "    output_shape = len(y[0])\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Model(input_shape, output_shape)\n",
    "    early_stopping = EarlyStopping(.001, 5)\n",
    "    train(model, train_dataloader, validation_dataloader, 5e-7, 1e-3, early_stopping, .6, device)\n",
    "    best_model = model\n",
    "    best_model.load_state_dict(early_stopping.best_model.state_dict())\n",
    "    models.append(best_model)\n",
    "    best_model.eval()\n",
    "    best_model.to(device)\n",
    "    trues = []\n",
    "    preds = []\n",
    "    e = lambda x: torch.max(x, -1)[1].view(-1).cpu()\n",
    "    with torch.no_grad():\n",
    "        for _, (current_x, current_y) in enumerate(validation_dataloader):\n",
    "            current_x = current_x.to(device)\n",
    "            y_pred = best_model(current_x)\n",
    "            preds += e(y_pred)\n",
    "            trues += e(current_y)\n",
    "            del y_pred\n",
    "            del current_x\n",
    "    print(f\"final accuracy for validation (fold {fold}): {accuracy_score(trues, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear_0): Linear(in_features=772, out_features=3088, bias=True)\n",
       "  (linear_1): Linear(in_features=3088, out_features=2316, bias=True)\n",
       "  (linear_2): Linear(in_features=2316, out_features=1544, bias=True)\n",
       "  (linear_3): Linear(in_features=1544, out_features=772, bias=True)\n",
       "  (linear_4): Linear(in_features=772, out_features=40, bias=True)\n",
       "  (linear_5): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (linear_6): Linear(in_features=20, out_features=12, bias=True)\n",
       "  (output): Linear(in_features=12, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, test_buckets = []):\n",
    "    BUCKETS = 10\n",
    "\n",
    "    N_ELEMENTS = len(data)\n",
    "\n",
    "    BUCKET_SIZE = N_ELEMENTS // BUCKETS\n",
    "\n",
    "    local = data.copy()\n",
    "    test = []\n",
    "    \n",
    "    for bucket in test_buckets:\n",
    "        idx = bucket * BUCKET_SIZE\n",
    "        for _ in range(BUCKET_SIZE):\n",
    "            test.append(local.pop(idx))\n",
    "\n",
    "    train_elements = (len(local) // 10) * 9\n",
    "    train = local[:train_elements]\n",
    "\n",
    "    validation = local[train_elements:]\n",
    "\n",
    "    \n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, model, combinations, desc):\n",
    "    tot_time = 0\n",
    "    combs = {comb:0 for comb in combinations}\n",
    "    trues = []\n",
    "    preds = []\n",
    "    for datapoint in tqdm.tqdm(dataset, desc):\n",
    "        instance = datapoint[\"instance_name\"]\n",
    "        features = df[df[\"inst\"] == instance].to_dict()\n",
    "        idx = list(features[\"inst\"].keys())[0]\n",
    "        features = {key: features[key][idx] for key in features.keys()}\n",
    "        keys = list(features.keys())\n",
    "        keys.pop(keys.index(\"inst\"))\n",
    "        keys.pop(keys.index(\"time\"))\n",
    "        features = [features[key] for key in keys]\n",
    "        x = torch.tensor(features)\n",
    "        x = x.to(device)\n",
    "        y_pred = model(x)\n",
    "        del x\n",
    "        y_pred = int(torch.max(y_pred, -1)[1].view(-1).cpu())\n",
    "        comb = combinations[y_pred]\n",
    "        times = {t[\"combination\"]: t[\"time\"] for t in datapoint[\"all_times\"]}\n",
    "        tot_time += times[comb]\n",
    "        for key in times:\n",
    "            combs[key] += times[key]\n",
    "        trues.append(combinations.index(datapoint[\"combination\"]))\n",
    "        preds.append(y_pred)\n",
    "    print(f\"accuracy: {accuracy_score(trues, preds):2f}\")\n",
    "    return tot_time, combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train fold: 0: 100%|██████████| 1809/1809 [00:54<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.559978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation fold: 0: 100%|██████████| 204/204 [00:06<00:00, 31.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.588235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test fold: 0: 100%|██████████| 223/223 [00:06<00:00, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.582960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train fold: 1: 100%|██████████| 1809/1809 [00:53<00:00, 34.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.420674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation fold: 1: 100%|██████████| 204/204 [00:06<00:00, 31.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.406863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test fold: 1: 100%|██████████| 223/223 [00:07<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.390135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train fold: 2: 100%|██████████| 1809/1809 [00:51<00:00, 35.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.800442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation fold: 2: 100%|██████████| 204/204 [00:06<00:00, 31.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test fold: 2: 100%|██████████| 223/223 [00:06<00:00, 35.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.744395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folds_data = {}\n",
    "for fold in [0,1,2]:\n",
    "    train_data, validaion_data, test_data = get_data(dataset, [fold])\n",
    "    model = models[fold]\n",
    "    with torch.no_grad():\n",
    "        tot_time_train, combs_train = test(train_data, model, combinations, f\"train fold: {fold}\")\n",
    "        tot_time_val, combs_val = test(validaion_data, model, combinations, f\"validation fold: {fold}\")\n",
    "        tot_time_test, combs_test = test(test_data, model, combinations, f\"test fold: {fold}\")\n",
    "        folds_data[fold] = {\"train\": {\"time\": tot_time_train, \"combs\": combs_train}, \"validation\": {\"time\": tot_time_val, \"combs\": combs_val}, \"test\": {\"time\": tot_time_test, \"combs\": combs_test}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0 - train]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 34,669.20\n",
      "pred time: 403,799.53\n",
      "pred/sb:11.65\n",
      "-------------------------------\n",
      "[fold 0 - validation]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 4,888.05\n",
      "pred time: 76,120.45\n",
      "pred/sb:15.57\n",
      "-------------------------------\n",
      "[fold 0 - test]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 4,288.49\n",
      "pred time: 7,757.74\n",
      "pred/sb:1.81\n",
      "-------------------------------\n",
      "====================================\n",
      "[fold 1 - train]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 33,382.17\n",
      "pred time: 331,066.31\n",
      "pred/sb:9.92\n",
      "-------------------------------\n",
      "[fold 1 - validation]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 4,888.05\n",
      "pred time: 76,124.49\n",
      "pred/sb:15.57\n",
      "-------------------------------\n",
      "[fold 1 - test]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 5,575.52\n",
      "pred time: 77,383.14\n",
      "pred/sb:13.88\n",
      "-------------------------------\n",
      "====================================\n",
      "[fold 2 - train]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 33,907.66\n",
      "pred time: 97,527.99\n",
      "pred/sb:2.88\n",
      "-------------------------------\n",
      "[fold 2 - validation]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 4,888.05\n",
      "pred time: 4,333.59\n",
      "pred/sb:0.89\n",
      "-------------------------------\n",
      "[fold 2 - test]\n",
      "sb combination: kissat_01_compact.eprime\n",
      "sb time: 5,050.03\n",
      "pred time: 39,457.34\n",
      "pred/sb:7.81\n",
      "-------------------------------\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "for fold in [0, 1, 2]:\n",
    "    data = folds_data[fold]\n",
    "    for dataset in [\"train\", \"validation\", \"test\"]:\n",
    "        dataset_data = data[dataset]\n",
    "        combs = dataset_data[\"combs\"]\n",
    "        tot_time = dataset_data[\"time\"]\n",
    "        sb_model, sb_time = min(combs.items(), key = lambda x: x[1])\n",
    "        print(f\"\"\"[fold {fold} - {dataset}]\n",
    "sb combination: {sb_model}\n",
    "sb time: {sb_time:,.2f}\n",
    "pred time: {tot_time:,.2f}\n",
    "pred/sb:{tot_time/sb_time:,.2f}\n",
    "-------------------------------\"\"\")\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31799.43999999997\n",
    "33905.89000000003\n",
    "43845.739999999976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2236/2236 [00:00<00:00, 5036768.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31799.43999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vb = 0\n",
    "for datapoint in tqdm.tqdm(dataset):\n",
    "    vb += datapoint[\"time\"]\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
