from .base_predictor import Predictor, Predictor_initializer
from tqdm import tqdm
from sys import stderr
import platform
import concurrent.futures
import re
import subprocess
import pandas as pd
import os
from time import time
import uuid

class Autofolio_initializer(Predictor_initializer):
    def __init__(self, model:'str', max_threads:'int') -> None:
        super().__init__()
        self.model = model
        self.max_threads = max_threads

class Autofolio_predictor(Predictor):
    
    MODEL_NAME = "autofolio_random_forest_model"
    CACHE_DIR = ".cache"
    PERSONAL_UUID = uuid.uuid4()

    def __init__(self, training_data:'list[dict]|None', 
                 features:'pd.DataFrame|None', 
                 tune:'bool' = False,
                 max_threads:'int' = 12,
                 pre_trained_model:'str|None' = None
        ) -> 'None':
        """
        initialize an instance of the class Recall_predictor.
        ---------
        Parameters
            training_data:list[dict].
                Indicates the data to use to create the ordering used to break ties
            idx2comb:dict[int,str].
                A dictionary that, for each index, returns the corresponding combination
            features:pd.DataFrame.
                a dataframe with a column indicating the instances and a feature set for each feature
            hyperparameters:dict|None. Default=None
                hyperparameters of the clustering model to use. If None, a greedy search will be done to find the best hyperparameters
        -----
        Usage
        ```py
        train_data = [{"inst": "instance name", "trues":[1,0,1,0]}]
        fatures = pd.DataFrame([{"inst": "instance name", "feat1":0, "feat2":0, "feat3":1, "feat4":1}])
        idx2comb = {0: "combination_0", 1:"combination_1"}
        predictor = Clustering_predictor(train_data, idx2comb, features)
        ```
        """

        super().__init__()
        if training_data is None or features is None:
            return
        if "3.6" not in platform.python_version():
            raise Exception(f"AUtofolio works only on python version 3.6.x. found {platform.python_version()}")

        self.max_threads = max_threads
        if pre_trained_model is None:
            if not os.path.isdir(self.CACHE_DIR):
                os.makedirs(self.CACHE_DIR)

            times_file = os.path.join(self.CACHE_DIR, f"train_times_{self.PERSONAL_UUID}.csv")
            pre_trained_model = os.path.join(self.CACHE_DIR, f"{self.MODEL_NAME}_{self.PERSONAL_UUID}")
            features_file = os.path.join(self.CACHE_DIR, f"train_features_{self.PERSONAL_UUID}.csv")

            x_header = list(features.columns)
            x_train_file = self.__create_file(features_file)
            x_train_file.write(",".join(x_header) + "\n")
            x_train = [[str(f) for f in features[features["inst"] == datapoint["inst"]].to_numpy()[0].tolist()] for datapoint in training_data]
            times = {opt:0 for opt in training_data[0]["times"].keys()}
            for i in range(len(training_data)):
                inst = training_data[i]["inst"]
                x_train[i].pop(x_train[i].index(inst))
                x_train[i] = [inst] + x_train[i]
                for key in training_data[i]["times"].keys():
                    times[key] += training_data[i]["times"][key]

            self.sb = min(times.items())[0]
            
            self.__save(x_train, x_train_file)
            x_train_file.close()
            combinations = sorted(list(training_data[0]["times"].keys()))
            y_header = ["inst"] + combinations
            y_train_file = self.__create_file(times_file)
            y_train_file.write(",".join(y_header) + "\n")
            y_train = [[datapoint["inst"]] + [str(datapoint["times"][comb]) for comb in combinations] for datapoint in training_data]
            self.__save(y_train, y_train_file)
            y_train_file.close()
            
            if tune:
                subprocess.run(
                    ["python", "AutoFolio/scripts/autofolio",
                     "--performance_csv", times_file, "--feature_csv", features_file, "--output_dir", f"{self.PERSONAL_UUID}",
                     "-t","--wallclock_limit", str(18000), "--runcount_limit", str(999999999), "--save", pre_trained_model])
                print(f"personal UUID: {self.PERSONAL_UUID}")
            else:
                subprocess.run(
                    ["python", "AutoFolio/scripts/autofolio", 
                    "--performance_csv", times_file, "--feature_csv", features_file, "--save", pre_trained_model])

        self.model = pre_trained_model

    @staticmethod
    def from_pretrained(pretrained:'Autofolio_initializer') -> 'Autofolio_predictor':
        predictor = Autofolio_predictor(None, None)
        predictor.model = pretrained.model
        predictor.max_threads = pretrained.max_threads
        return predictor

    def __create_file(self, file_name):
        f = open(file_name, "w")
        f.write("")
        f.close()
        return open(file_name, "a")

    def __save(self, data, file):
        for d in data:
            file.write(f"{','.join(d)}\n")

    def __get_prediction(self, options:'list', inst:'str'):
        start = time()
        options = [str(o) for o in options]
        out = subprocess.run(['python3', 'AutoFolio/scripts/autofolio', '--load', self.model, '--feature_vec', f'{" ".join(options)}'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        out = out.stdout.decode('utf-8')
        chosen_option = re.findall(r"\[\('([a-zA-Z0-9.,-_]*)', [0-9]*\)\]", out)
        if len(chosen_option) == 0:
            raise Exception(out)
        return chosen_option[0], inst, time() - start

    def __get_dataset(self, dataset:'list') -> 'list[dict]':
        if type(dataset[0]) == float:
            return [{"inst":"", "features":dataset}]
        return dataset

    def predict(self, dataset:'list[dict]|list[float]', filter:'bool'=False) -> 'list[dict]|dict':
        """
        Given a dataset, return a list containing each prediction for each datapoint and the sum of the total predicted time.
        -------
        Parameters
            dataset:list[dict]
                A list containing, for each datapoint to predict, a list of features to use for the prediction, a dictionary containing, for each option, the corresponding time
        ------
        Output
            A tuple containing:
                - a list of dicts with, for each datapoint, the chosen option and the corresponding predicted time
                - a float corresponding to the total time of the predicted options
        """

        is_single = type(dataset[0]) == float
        dataset = self.__get_dataset(dataset)

        if filter != False:
            print("WARNING: predictor Autofolio cannot pre-filter option", file=stderr)
        predictions = []
        with concurrent.futures.ThreadPoolExecutor(self.max_threads) as executor:
            futures = {executor.submit(self.__get_prediction,datapoint["features"], datapoint["inst"]): datapoint["inst"] for datapoint in dataset}

            for future in tqdm(concurrent.futures.as_completed(futures)):
                text = futures[future]
                try:
                    result = future.result()
                    predictions.append({"chosen_option": result[0], "inst": result[1], "time": result[2]})
                except Exception as e:
                    print(f"An error occurred for text '{text}': {e}", file=stderr)

        if is_single:
            return predictions[0]
        return predictions
    
    def predict_sequential(self, dataset:'list[dict]') -> 'list[dict]|dict':
        predictions = []
        for datapoint in tqdm(dataset):
            try:
                prediction = self.__get_prediction(datapoint["features"], datapoint["inst"])
                predictions.append({"chosen_option": prediction[0], "inst": prediction[1], "time": prediction[2]})
            except Exception as e:
                print(f"An error occurred for text '{datapoint['inst']}': {e}", file=stderr)
        return predictions
    
